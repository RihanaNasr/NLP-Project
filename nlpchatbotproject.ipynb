{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2350014,"sourceType":"datasetVersion","datasetId":1418725}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\nimport re","metadata":{"execution":{"iopub.status.busy":"2025-05-11T02:55:18.470953Z","iopub.execute_input":"2025-05-11T02:55:18.471251Z","iopub.status.idle":"2025-05-11T02:55:28.061093Z","shell.execute_reply.started":"2025-05-11T02:55:18.471213Z","shell.execute_reply":"2025-05-11T02:55:28.060020Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"data_df= pd.read_csv('/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/dialogs_expanded.csv', index_col=False)","metadata":{"execution":{"iopub.status.busy":"2025-05-11T02:55:28.063414Z","iopub.execute_input":"2025-05-11T02:55:28.064088Z","iopub.status.idle":"2025-05-11T02:55:29.806606Z","shell.execute_reply.started":"2025-05-11T02:55:28.064054Z","shell.execute_reply":"2025-05-11T02:55:29.805488Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:17.333792Z","iopub.execute_input":"2023-07-24T03:34:17.334362Z","iopub.status.idle":"2023-07-24T03:34:17.364516Z","shell.execute_reply.started":"2023-07-24T03:34:17.334319Z","shell.execute_reply":"2023-07-24T03:34:17.363504Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_df.drop(['Unnamed: 0','question_as_int','answer_as_int','question_len','answer_len'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:18.430315Z","iopub.execute_input":"2023-07-24T03:34:18.430681Z","iopub.status.idle":"2023-07-24T03:34:18.459047Z","shell.execute_reply.started":"2023-07-24T03:34:18.430651Z","shell.execute_reply":"2023-07-24T03:34:18.458026Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:19.639313Z","iopub.execute_input":"2023-07-24T03:34:19.640191Z","iopub.status.idle":"2023-07-24T03:34:19.75374Z","shell.execute_reply.started":"2023-07-24T03:34:19.640159Z","shell.execute_reply":"2023-07-24T03:34:19.752645Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:20.647168Z","iopub.execute_input":"2023-07-24T03:34:20.649739Z","iopub.status.idle":"2023-07-24T03:34:20.661493Z","shell.execute_reply.started":"2023-07-24T03:34:20.649706Z","shell.execute_reply":"2023-07-24T03:34:20.660453Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:21.550195Z","iopub.execute_input":"2023-07-24T03:34:21.550904Z","iopub.status.idle":"2023-07-24T03:34:21.561817Z","shell.execute_reply.started":"2023-07-24T03:34:21.550871Z","shell.execute_reply":"2023-07-24T03:34:21.560474Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:22.465001Z","iopub.execute_input":"2023-07-24T03:34:22.465388Z","iopub.status.idle":"2023-07-24T03:34:22.483358Z","shell.execute_reply.started":"2023-07-24T03:34:22.465356Z","shell.execute_reply":"2023-07-24T03:34:22.482286Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clean_text(text):\n  text = text.lower()\n  text = re.sub('\\[.*?\\]', '', text)\n  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n  text = re.sub('<.*?>+', '', text)\n  text = re.sub('\\n', '', text)\n  text = re.sub(r'[^\\w]',' ',text)\n  text = re.sub('\\w*\\d\\w*', '', text)\n  return text\n\ndata_df.question = data_df.question.map(clean_text)\ndata_df.answer = data_df.answer.map(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:23.218647Z","iopub.execute_input":"2023-07-24T03:34:23.219007Z","iopub.status.idle":"2023-07-24T03:34:29.329844Z","shell.execute_reply.started":"2023-07-24T03:34:23.218979Z","shell.execute_reply":"2023-07-24T03:34:29.328798Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_start_end(text):\n  text = f'<start> {text} <end>'\n  return text\n\ndata_df.question = data_df.question.map(add_start_end)\ndata_df.answer = data_df.answer.map(add_start_end)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:31.217362Z","iopub.execute_input":"2023-07-24T03:34:31.217779Z","iopub.status.idle":"2023-07-24T03:34:31.362042Z","shell.execute_reply.started":"2023-07-24T03:34:31.217748Z","shell.execute_reply":"2023-07-24T03:34:31.360931Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:32.187952Z","iopub.execute_input":"2023-07-24T03:34:32.188348Z","iopub.status.idle":"2023-07-24T03:34:32.200968Z","shell.execute_reply.started":"2023-07-24T03:34:32.188318Z","shell.execute_reply":"2023-07-24T03:34:32.199786Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize(lang):\n  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n      filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<OOV>'\n  )\n  lang_tokenizer.fit_on_texts(lang)\n  tensor = lang_tokenizer.texts_to_sequences(lang)\n  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n  return tensor, lang_tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:33.162142Z","iopub.execute_input":"2023-07-24T03:34:33.162821Z","iopub.status.idle":"2023-07-24T03:34:33.168805Z","shell.execute_reply.started":"2023-07-24T03:34:33.162789Z","shell.execute_reply":"2023-07-24T03:34:33.167624Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question_sequence, question_tokenizer = tokenize(data_df.question)\nanswer_sequence, answer_tokenizer = tokenize(data_df.answer)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:34.231415Z","iopub.execute_input":"2023-07-24T03:34:34.231775Z","iopub.status.idle":"2023-07-24T03:34:44.645169Z","shell.execute_reply.started":"2023-07-24T03:34:34.231744Z","shell.execute_reply":"2023-07-24T03:34:44.644175Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = model_selection.train_test_split(question_sequence, \n                answer_sequence, test_size = 0.1, random_state=42) \n\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:47.685056Z","iopub.execute_input":"2023-07-24T03:34:47.68542Z","iopub.status.idle":"2023-07-24T03:34:47.729072Z","shell.execute_reply.started":"2023-07-24T03:34:47.685391Z","shell.execute_reply":"2023-07-24T03:34:47.727942Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert(lang, tensor):\n  for t in tensor:\n    if t!=0:\n      print('%d---> %s' % (t, lang.index_word[t]))\n\nprint('Question')\nconvert(question_tokenizer, x_train[0])\nprint()\nprint('Answer')\nconvert(answer_tokenizer, y_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:49.555529Z","iopub.execute_input":"2023-07-24T03:34:49.555877Z","iopub.status.idle":"2023-07-24T03:34:49.563422Z","shell.execute_reply.started":"2023-07-24T03:34:49.555849Z","shell.execute_reply":"2023-07-24T03:34:49.562287Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vocab_inp_size = len(question_tokenizer.word_index)+1\nvocab_tar_size =  len(answer_tokenizer.word_index)+1\nembedding_dim = 256\nunits = 1024\nbatch_size=32","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:50.654371Z","iopub.execute_input":"2023-07-24T03:34:50.654738Z","iopub.status.idle":"2023-07-24T03:34:50.660002Z","shell.execute_reply.started":"2023-07-24T03:34:50.65471Z","shell.execute_reply":"2023-07-24T03:34:50.658778Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_dataset(x, y, batch_size=32):\n  data = tf.data.Dataset.from_tensor_slices((x, y))\n\n  data = data.shuffle(1028)\n  data = data.batch(batch_size, drop_remainder=True)\n\n  data = data.prefetch(tf.data.experimental.AUTOTUNE)\n\n  return data\n\ntrain_dataset = create_dataset(x_train, y_train)\ntest_dataset = create_dataset(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:52.033169Z","iopub.execute_input":"2023-07-24T03:34:52.033889Z","iopub.status.idle":"2023-07-24T03:34:56.576164Z","shell.execute_reply.started":"2023-07-24T03:34:52.033855Z","shell.execute_reply":"2023-07-24T03:34:56.575114Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"  for q, a in train_dataset.take(1):\n    print(f'Question:{q.shape}\\n{q}')\n  \n    print(f'Answer:{a.shape}\\n{a}')","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:56.578267Z","iopub.execute_input":"2023-07-24T03:34:56.578622Z","iopub.status.idle":"2023-07-24T03:34:56.677025Z","shell.execute_reply.started":"2023-07-24T03:34:56.578589Z","shell.execute_reply":"2023-07-24T03:34:56.675922Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Encoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n      super(Encoder, self).__init__()\n\n      self.batch_size = batch_size\n      self.encoder_units = encoder_units\n      self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n      self.gru = tf.keras.layers.GRU(self.encoder_units, \n                                           return_sequences=True,\n                                           return_state=True,\n                                           recurrent_initializer = 'glorot_uniform')\n\n  def call(self, x, hidden):\n    x = self.embedding(x)\n    output, state = self.gru(x, initial_state = hidden)\n    return output, state\n\n  def initialize_hidden_state(self):\n    return tf.zeros((self.batch_size, self.encoder_units))","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:56.678659Z","iopub.execute_input":"2023-07-24T03:34:56.679Z","iopub.status.idle":"2023-07-24T03:34:56.687717Z","shell.execute_reply.started":"2023-07-24T03:34:56.678969Z","shell.execute_reply":"2023-07-24T03:34:56.68655Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n      super(Decoder, self).__init__()\n\n      self.batch_size = batch_size\n      self.decoder_units = decoder_units\n      self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n      self.gru = tf.keras.layers.GRU(self.decoder_units, \n                                           return_sequences=True,\n                                           return_state=True,\n                                           recurrent_initializer = 'glorot_uniform')\n      \n      self.fc = tf.keras.layers.Dense(vocab_size)\n\n\n  def call(self, x, hidden):\n    x = self.embedding(x)\n    output, hidden = self.gru(x, initial_state = hidden)\n    output = tf.reshape(output, (-1, output.shape[2]))\n    x =  tf.nn.softmax(self.fc(output))\n    return x, hidden","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:56.690701Z","iopub.execute_input":"2023-07-24T03:34:56.691539Z","iopub.status.idle":"2023-07-24T03:34:56.701592Z","shell.execute_reply.started":"2023-07-24T03:34:56.691502Z","shell.execute_reply":"2023-07-24T03:34:56.700518Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# vocab_inp_size = len(eng_tokenizer.word_index)+1\n# vocab_tar_size =  len(spn_tokenizer.word_index)+1\n# embedding_dim = 256\n# units = 1024\n# batch_size=32\n\nencoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size)\nsample_hidden = encoder.initialize_hidden_state()\nsample_output, sample_hidden = encoder(q, sample_hidden)\nprint ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\nprint ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:34:57.533101Z","iopub.execute_input":"2023-07-24T03:34:57.533521Z","iopub.status.idle":"2023-07-24T03:35:01.247049Z","shell.execute_reply.started":"2023-07-24T03:34:57.533488Z","shell.execute_reply":"2023-07-24T03:35:01.245936Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"decoder = Decoder(vocab_tar_size, embedding_dim, units, batch_size)\n\nsample_decoder_output, _ = decoder(tf.random.uniform((batch_size, 1)), sample_hidden)\n\nprint ('Decoder output shape: (batch size, vocab_size) {}'.format(sample_decoder_output.shape))","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:35:01.252645Z","iopub.execute_input":"2023-07-24T03:35:01.255698Z","iopub.status.idle":"2023-07-24T03:35:01.368147Z","shell.execute_reply.started":"2023-07-24T03:35:01.25566Z","shell.execute_reply":"2023-07-24T03:35:01.366885Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create the optimizer using the Adam optimizer\noptimizer = tf.keras.optimizers.Adam()\n# create the loss function\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=False, reduction='none')\n\n# define the loss function for the training\ndef loss_function(real, pred):\n  # create the mask to ignore the padding tokens\n  mask = tf.math.logical_not(tf.math.equal(real, 0))\n  # mask shape == (batch_size, sequence_length)\n  # calculate the loss\n  loss_ = loss_object(real, pred)\n  # mask the loss\n  # how the mask works:\n  # if the value is 1, the loss is calculated\n  # if the value is 0, the loss is ignored\n    #[1,1,1,1,1,1,0,0,0,0,0] mask\n    # *\n    #[2,6,2,1,6,3,2,1,5,7,9] input\n    # =\n    #[2,6,2,1,6,3,0,0,0,0,0] output\n  mask = tf.cast(mask, dtype=loss_.dtype)\n  # mask shape == (batch_size, sequence_length)\n\n  loss_ *= mask\n  # calculate the average loss per batch \n  return tf.reduce_mean(loss_)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:35:03.910085Z","iopub.execute_input":"2023-07-24T03:35:03.910806Z","iopub.status.idle":"2023-07-24T03:35:03.924292Z","shell.execute_reply.started":"2023-07-24T03:35:03.910773Z","shell.execute_reply":"2023-07-24T03:35:03.923032Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create the training metric \ntrain_loss = tf.metrics.Mean(name='train loss')\n# create the testing metric \ntest_loss =tf.metrics.Mean(name='test loss')","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:35:08.756579Z","iopub.execute_input":"2023-07-24T03:35:08.757443Z","iopub.status.idle":"2023-07-24T03:35:08.772013Z","shell.execute_reply.started":"2023-07-24T03:35:08.7574Z","shell.execute_reply":"2023-07-24T03:35:08.771057Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create the training step\n# using the tf.function decorator to speed up the training process by converting the training function to a TensorFlow graph\n@tf.function\n# define the training step \ndef train_step(inputs, target, enc_hidden):\n  # the encoder_hidden is the initial hidden state of the encoder\n  # enc_hidden shape == (batch_size, hidden_size)\n\n  # inilaize the loss to zero\n  loss = 0\n  # create the gradient tape to record the gradient of the loss with respect to the weights\n\n  with tf.GradientTape() as tape:\n    # pass the input to the encoder\n    # enc_output shape == (batch_size, 49, hidden_size)\n    # enc_hidden shape == (batch_size, hidden_size)\n    # using the encoder to get the encoder_output and the encoder_hidden\n    # using the encoder_hidden as the initial hidden state of the decoder\n    enc_output, enc_hidden = encoder(inputs, enc_hidden)\n    # set the initial decoder hidden state to the encoder hidden state\n    dec_hidden = enc_hidden\n\n    # create the start token \n    # start_token shape == (batch_size, 1)\n    # repeat the start token for the batch size times\n    dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']] * inputs.shape[0], 1)\n    \n    # Teacher forcing - feeding the target as the next input\n    \n    for t in range(1, target.shape[1]):\n      # passing enc_output to the decoder\n      predictions, dec_hidden = decoder(dec_input, dec_hidden)\n      # calculate the loss for the current time step using the loss function\n      loss += loss_function(target[:, t], predictions)\n\n      # using teacher forcing\n      dec_input = tf.expand_dims(target[:, t], 1)\n  # calculate the loss for the current batch\n  batch_loss = (loss / int(target.shape[1]))\n\n  # get the trainable variables\n  variables = encoder.trainable_variables + decoder.trainable_variables\n  # calculate the gradients using the tape \n  gradients = tape.gradient(loss, variables)\n  # update the trainable variables\n  optimizer.apply_gradients(zip(gradients, variables))\n  # add the loss to the training loss metric\n  train_loss(batch_loss)\n  return batch_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:35:22.345378Z","iopub.execute_input":"2023-07-24T03:35:22.346487Z","iopub.status.idle":"2023-07-24T03:35:22.357296Z","shell.execute_reply.started":"2023-07-24T03:35:22.346441Z","shell.execute_reply":"2023-07-24T03:35:22.356007Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create the training step\n# using the tf.function decorator to speed up the training process by converting the training function to a TensorFlow graph\n@tf.function \ndef test_step(inputs, target, enc_hidden):\n    # the encoder_hidden is the initial hidden state of the encoder\n    # enc_hidden shape == (batch_size, hidden_size)\n    # inilaize the loss to zero\n    loss = 0\n    # pass the input to the encoder \n    # enc_output shape == (batch_size, 49, hidden_size) \n    # enc_hidden shape == (batch_size, hidden_size)\n    # using the encoder to get the encoder_output and the encoder_hidden\n    enc_output, enc_hidden = encoder(inputs, enc_hidden)\n    # set the initial decoder hidden state to the encoder hidden state\n    dec_hidden = enc_hidden\n    # create the start token\n    # start_token shape == (batch_size, 1)\n    # repeat the start token for the batch size times\n    dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']] * inputs.shape[0], 1)\n    for t in range(1, target.shape[1]):\n        # passing enc_output to the decoder with dec_hidden as the initial hidden state\n        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n        # calculate the loss for the current time step using the loss function \n        loss += loss_function(target[:, t], predictions)\n\n        # using teacher forcing\n        dec_input = tf.expand_dims(target[:, t], 1)\n    # calculate the loss for the current batch\n    batch_loss = (loss / int(target.shape[1]))\n    # add the batch loss to the test loss metric\n    test_loss(batch_loss)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:35:26.58098Z","iopub.execute_input":"2023-07-24T03:35:26.581395Z","iopub.status.idle":"2023-07-24T03:35:26.589943Z","shell.execute_reply.started":"2023-07-24T03:35:26.581357Z","shell.execute_reply":"2023-07-24T03:35:26.588671Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# set the epochs to 10\nEPOCHS = 10\n# set the old test loss to high number \n\nold_test_loss=1000000\n# create the training loop\nfor epoch in range(EPOCHS):\n    # reset the training loss metric\n    train_loss.reset_states()\n    # reset the testing loss metric\n    test_loss.reset_states()\n\n    # initalize the hidden state of the encoder to zeros \n    enc_hidden = encoder.initialize_hidden_state()\n    # create the training progress bar set the total number of batches to the length of the training dataset and the batch size to the test size\n    steps_per_epoch = answer_sequence.shape[0]//batch_size #=> 4356 batch in the dataset \n    bar = tf.keras.utils.Progbar(target=steps_per_epoch)\n    \n    count=0\n    # iterate over the training dataset \n    for (batch, (inputs, target)) in enumerate(train_dataset):\n        # update the progress bar\n     count += 1\n        # run the training step\n     batch_loss = train_step(inputs, target, enc_hidden)\n     bar.update(count)  # manually update the progress bar\n                                                  \n    \n    \n    # iterate over the testing dataset    \n    for (batch, (inputs, target)) in enumerate(test_dataset):\n     count += 1\n        # run the testing step\n     batch_loss = test_step(inputs, target, enc_hidden)\n    bar.update(count)\n    # save the best performance model on the test dataset \n    \n    if old_test_loss> test_loss.result():\n        # set the old test loss to the test loss \n        old_test_loss= test_loss.result()\n        encoder.save(filepath='/content/models/encoder')\n        decoder.save(filepath='/content/models/decoder')\n        print('Model is saved')\n    # print the training and testing loss\n    print('#' * 50)\n    print(f'Epoch #{epoch + 1}')\n    print(f'Training Loss {train_loss.result()}')\n    print(f'Testing Loss {test_loss.result()}')\n    print('#' * 50)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T03:35:34.426393Z","iopub.execute_input":"2023-07-24T03:35:34.4268Z","iopub.status.idle":"2023-07-24T06:07:26.86449Z","shell.execute_reply.started":"2023-07-24T03:35:34.426769Z","shell.execute_reply":"2023-07-24T06:07:26.863446Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create the chatbot function\n# the chatbot function takes in the question as input and answers the input sentence \ndef chatbot(sentence):\n  \n  # clean the input question sentence \n  sentence = clean_text(sentence)\n  # add the start token to the sentence\n  sentence =add_start_end(sentence)\n  # tokenize the sentence\n  inputs = question_tokenizer.texts_to_sequences([sentence])\n  # pad the sentence\n  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n                                                         maxlen=29,\n                                                         padding='post')\n  \n  # initalize the hidden state of the encoder to zeros\n  hidden = [tf.zeros((1, units))]\n  # pass the sentence to the encoder with the hidden state as the initial hidden state\n  enc_out, enc_hidden = encoder(inputs, hidden)\n  # set the initial decoder hidden state to the encoder hidden state\n  dec_hidden = enc_hidden\n  # create the start token\n  # start_token shape == (batch_size, 1)\n  # repeat the start token for the batch size times\n  dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']], 0)\n  # create the result string\n  result = ''\n  # loop over the length of the sentence (32)\n\n  for t in range(32):\n    # passing the encoder output and the decoder hidden state to the decoder make sure the decoder input is the previous predicted word\n    predictions, dec_hidden = decoder(dec_input, dec_hidden)\n\n    # getting the predicted word index\n    predicted_id = tf.argmax(predictions[0]).numpy()\n    # getting the predicted word using the predicted index\n    # add the predicted word to the result string \n    result += answer_tokenizer.index_word[predicted_id] + ' '\n    # if the predicted word is the <end> token then stop the loop\n    if answer_tokenizer.index_word[predicted_id] == '<end>':\n      # remove the <start> and <end> tokens from the result string\n      result = result.replace('<start> ', '')\n      result = result.replace(' <end> ','')\n      # remove the <start> and <end> tokens from the sentence string\n      sentence = sentence.replace('<start> ', '')\n      sentence = sentence.replace(' <end>', '')\n      return  sentence, result\n\n    # using the predicted word as the next decoder input\n    dec_input = tf.expand_dims([predicted_id], 0)\n  # remove the <start> and <end> tokens from the result string\n  result = result.replace('<start> ', '')\n  result = result.replace('<end>','')\n  # remove the <start> and <end> tokens from the sentence string\n  sentence = sentence.replace('<start> ', '')\n  sentence = sentence.replace('<end>', '')\n  \n\n  \n \n  \n  # return the result string and the original sentence\n  return sentence, result","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:09:53.882538Z","iopub.execute_input":"2023-07-24T06:09:53.882927Z","iopub.status.idle":"2023-07-24T06:09:53.894961Z","shell.execute_reply.started":"2023-07-24T06:09:53.882891Z","shell.execute_reply":"2023-07-24T06:09:53.893872Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatbot(\"how are you today\")","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:10:25.156506Z","iopub.execute_input":"2023-07-24T06:10:25.156872Z","iopub.status.idle":"2023-07-24T06:10:25.203154Z","shell.execute_reply.started":"2023-07-24T06:10:25.156843Z","shell.execute_reply":"2023-07-24T06:10:25.20227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatbot('what is the weather outside')","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:10:29.479239Z","iopub.execute_input":"2023-07-24T06:10:29.480119Z","iopub.status.idle":"2023-07-24T06:10:29.561738Z","shell.execute_reply.started":"2023-07-24T06:10:29.480085Z","shell.execute_reply":"2023-07-24T06:10:29.560813Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatbot('can you run')","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:10:32.175811Z","iopub.execute_input":"2023-07-24T06:10:32.176549Z","iopub.status.idle":"2023-07-24T06:10:32.319138Z","shell.execute_reply.started":"2023-07-24T06:10:32.17651Z","shell.execute_reply":"2023-07-24T06:10:32.318155Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatbot(' how old ')","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:59.680338Z","iopub.execute_input":"2023-07-24T06:12:59.680777Z","iopub.status.idle":"2023-07-24T06:12:59.755338Z","shell.execute_reply.started":"2023-07-24T06:12:59.680744Z","shell.execute_reply":"2023-07-24T06:12:59.75416Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatbot('can you play')","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:13:50.280104Z","iopub.execute_input":"2023-07-24T06:13:50.281276Z","iopub.status.idle":"2023-07-24T06:13:50.364179Z","shell.execute_reply.started":"2023-07-24T06:13:50.281213Z","shell.execute_reply":"2023-07-24T06:13:50.36325Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}